# A véletlen ingadozás kérdésköre

## A véletlen ingadozás szerepe, a gyógyszer hatásának statisztikai szignifikanciája

Térjünk most vissza arra a -- korábban függőben hagyott -- kérdésre, hogy miért kell nagyobb létszámú csoportokat képeznünk. A helyzet megértéséhez képzeljük el, hogy egy bizonyos betegségben kezelés nélkül az alanyok 20%-a hal meg adott időn belül. Hány ember fog egy 100 fős betegcsoportból meghalni? Ha a betegek halála független egymástól, akkor ez úgy fogható fel, mintha lenne egy nagy urnánk, benne a golyók 20%-a piros, 80%-a fehér, mi pedig véletlenszerűen, azaz alapos megkeverés után kihúznánk belőle 100 golyót és megszámolnánk, hogy hány pirosat húztunk. Az ember érzése, hogy a legvalószínűbb, hogy 20-at, és ez a benyomás igaz is. De ha magunk elé képzeljük ezt a példát, akkor egy még fontosabb dolgot is látni fogunk: hogy ez csak a legvalószínűbb, de nem biztos! Húzhatunk 19 piros golyót, vagy 21-et is, pontosan úgy, ahogy ez szabályos pénzérmét 100-szor feldobva sem biztos, hogy *pont* 50 fejet és 50 írást dobunk. Lehet, hogy 19-en halnak meg, lehet, hogy 21-en, az is lehet, hogy 15-en, vagy 25-en, sőt, az is lehet, hogy senki, vagy mind a 100. Ez utóbbi esetek valószínűsége hihetetlenül kicsi -- de nem nulla.

Tegyük a kérdést izgalmasabbá! A gyógyszeres kezelés ezt a valószínűséget 10%-ra csökkenti, azaz a gyógyszer hatásos. Ez azt jelenti, hogy most két urnánk van, egy "kontroll" és egy "kezelt" feliratú, az előbbiben a golyók 20%-a piros, az utóbbiban csak 10%. Mit jelent egy klinikai vizsgálat a hatásosság eldöntésére? Azt, hogy mindkét urnából -- véletlenszerűen, alapos keverés után -- kihúzunk 100 golyót. Ha egy randomizált kísérletről van szó, semmilyen más hibaforrás nincs, akkor természetes lenne azt mondani, hogy a kezelés akkor tekinthető hatásosnak, ha a kezeltek között kisebb a halálozások aránya. De az urnás példa mutatja, hogy mi a probléma: *attól még*, mert az urnában 20%-10% az arány, *véletlenül* húzhatunk mindkettőből 15 pirosat! Az sem lehetetlen, hogy a 20%-os urnából 10, a 10%-osból 20 pirosat húzunk. Még egyszer: pusztán a véletlen szeszélye folytán!

Látható tehát, hogy kétirányú a probléma: ha a kezelt csoportban kevesebb halálozás lesz (kevesebb pirosat húzunk abból az urnából), akkor sem biztos, hogy hat a gyógyszer (kisebb a pirosak aránya az egész urnában), de ha ugyanannyit vagy épp többet húzunk, akkor sem lehetetlen, hogy mégis hat a gyógyszer. Ez a **véletlen ingadozás problémája**.

Fontos észrevétel, hogy a problémára tökéletes megoldás nincs: ha a kezeltek közül mindenki meggyógyul, és a kontrollcsoportból mindenki meghal, *elvileg* akkor is elképzelhető, hogy nem hat a gyógyszer. (Mindkét urnában a golyók fele piros, de az egyikből pont 100 pirosat, a másikból pont 100 fehéret húztunk -- pusztán a véletlen szeszélye folytán. Extrém valószínűtlen, de nem lehetetlen.) Ebben a helyzetben tehát *biztos* döntést nem tudunk hozni; ha ragaszkodnánk a biztos válaszhoz, akkor a kutatás minden eredménye esetén azt kellene mondani, hogy "nem tudjuk, hogy hat-e a gyógyszer". Ahhoz tehát, hogy egyáltalán válaszolni tudjunk a gyógyszer hatásosságára vonatkozó kérdésre, *muszáj* megengednünk valamennyi hibázást.

Valahol határt kell húznunk: már akkor mondjuk, hogy hat a gyógyszer, ha 20% helyett 19% hal meg? Vagy csak akkor, ha 15? Vagy még szigorúbbak vagyunk, és csak akkor, ha 5? Ezzel a döntéssel a kétféle hibázás között egyensúlyozunk: ha nagyon szigorúak vagyunk, akkor ritkán fogunk egy hatástalan gyógyszert tévesen hatásosnak minősíteni, de sokszor fogjuk a hatásosakra is azt mondani, hogy hatástalanok. Ha enyhék vagyunk, akkor pont fordítva.

Az orvosi vizsgálatok kiértékelését ma domináló statisztikai iskolában, amit frekventista iskolának szoktak nevezni, úgy húzzuk meg ezt a határt, hogy igaz legyen, hogy ha a gyógyszer nem hat, akkor csak adott, kicsi -- tipikusan 5% - valószínűséggel mondjuk mégis, a véletlen szeszélyéből fakadó tévedés folytán azt, hogy hat. Ezt az 5%-ot szokás szignifikanciaszintnek nevezni. Ha a gyógyszer az így meghúzott küszöbnél nagyobb hatást mutat, akkor azt mondjuk: statisztikailag **szignifikáns a hatás**. Értsd: nem tudható be a véletlen ingadozásnak, olyan nagy, hogy azt kell feltételeznünk, hogy az nem pusztán a véletlen ingadozás miatt jött ki.

Természetesen nem kötelező 5%-ot használni. Választhatunk más értéket is, például 1%-os szignifikanciaszintet: ez azt jelenti, hogy szigorúbb küszöböt szabunk meg, hiszen 1%-ra kell csökkenteni annak valószínűségét, hogy egy valójában nem hatásos gyógyszer pusztán a véletlen ingadozás miatt megugorja ezt a küszöböt. Azaz csak a vizsgálatunkban erősebben ható gyógyszerekre mondjuk azt, hogy "ez vélhetően nem a véletlen ingadozás miatt jött ki, miközben a valóságban nem hat a gyógyszer".

Kézenfekvő lenne a fenti, fordított logikával szemben a természetes kérdést feltenni, tehát azt, hogy "mennyire valószínű, hogy hat a gyógyszer". A fenti gondolkodási keretben azonban erre a kérdésre nem lehet válaszolni; ez már átvezet minket egy másik iskolába, melyet bayes-i statisztikának szokás nevezni. Sok érv szólna ennek használata mellett, de addig is, amíg elterjed, marad a "szignifikáns" szó használata, és az, hogy ne feledkezzünk meg erről a fordított logikáról: ha szignifikáns a gyógyszer hatása, az nem azt jelenti, hogy valószínű, hogy hat a gyógyszer, hanem azt, hogy ha nem hatna, akkor valószínűtlen lenne, hogy azt kapnánk a vizsgálatban, amit ténylegesen kaptunk is. Természetesen egyáltalán nem észszerűtlen ilyenkor azt mondani, hogy akkor "minden bizonnyal" hat a gyógyszer, de ettől még a dolog nem fordítható egyszerűen meg.

## A kutatás ereje és mintanagysága

Ha egyszer a szignifikanciaszint egy hibázás valószínűségét fejezi ki, és az értékét mi határozzuk meg, akkor miért 5%-ot használunk? Miért nem 1%-ot? (Így jóval kisebb lenne ennek a hibázásnak a valószínűsége!) Miért nem 0,1%-ot? Miért nem 0,01%-ot?

Hogy ezt megértsük, gondoljuk végig, hogy a szignifikanciaszint csökkentése mit jelentene: azt, hogy csak azokra a gyógyszerekre mondjuk, hogy hatnak, amelyek rendkívül hatásosnak bizonyulnak a vizsgálatban. Már egy közepes mértékű hatásra is azt mondjuk, hogy "ez még belefér a véletlen ingadozásba". Ez tényleg vitathatatlanul csökkenti annak a valószínűségét, hogy a hatástalan gyógyszereket tévedésből hatásosnak mondjuk, eddig rendben van, csak épp lenne egy kellemetlen következménye is: az, hogy a hatásos, nem extrém hatásos, de azért hatásos gyógyszerek egy nagy részére is azt mondanánk, hogy hatástalan! Hiszen nem tudják megugrani a nagyon magasra tett lécet.

A probléma tehát az, hogy a szignifikanciaszinttel az *egyik* típusú hibázás valószínűségéről nyilatkoztunk, arról, hogy ha nem hat a gyógyszer, mekkora valószínűséggel minősítjük mégis, pusztán a véletlen ingadozásból fakadó hiba folytán hatásosnak, de ezzel szemben áll egy másik típusú hibázás is: a hatásos gyógyszer téves hatástalannak minősítése. Mi a helyzet ennek a valószínűségével? Ez keményebb dió, hiszen ennek valószínűsége attól is függ, hogy *mennyire* hat a gyógyszer (amit mi magunk sem tudhatunk!). Minél hatásosabb, annál kisebb lesz ez a valószínűség.

Egy **kutatás erejének** nevezzük annak a valószínűségét, hogy a hatásos gyógyszert *helyesen* hatásosnak minősítjük. Az előbbiekből tehát látható, hogy ez függ a gyógyszer valódi hatásának mértékétől.

Nem kevésbé fontos, hogy függ a bevont betegek számától, a mintanagyságtól is: minél *több* betegünk van, a vizsgálatból kapott érték (a kihúzott golyók között a pirosak aránya) annál *kevésbé* ingadozik a valódi érték (a pirosak aránya az urnában) körül. Ez azért fontos, mert a korábban látott okfejtés azt mondja, hogy a szignifikancia azon múlik, hogy mennyire tudjuk igazolni, hogy a hatás nem fakadhatott véletlen ingadozásból -- ez pedig természetesen annál könnyebb, minél kisebb a véletlen ingadozás mértéke. Azaz: minél nagyobb a mintanagyság, annál nagyobb az erő.

A gyakorlatban erre az összefüggésre általában fordítva néznek rá: nem azt nézik, hogy adott mintanagyságnál mekkora az erő, hanem megkövetelnek egy adott erőt (tipikusan 80 vagy 90%), és azt számolják ki, hogy ennek eléréséhez mennyi beteg kell. Ez tehát lehetővé teszi egy vizsgálat mintanagyságának racionális megtervezését!

Természetesen, mint az az egész fenti okfejtésből is látszik, mindez függ attól, hogy mekkora a gyógyszer hatása, amit mi sem tudunk, ezért az egész mintanagyság-tervezés feltételes: *ha* a hatás nagysága ekkora, *akkor* ennyi beteg kell annak kimutatásához (adott erővel, adott szignifikanciaszinten). Az tehát egy fontos kérdés, hogy mit feltételezünk hatásnagyságnak, vagy pontosabb lenne úgy fogalmazni: mekkora hatás kimutatására szeretnénk képesek lenni (például az alapján, hogy mi klinikailag lényeges -- erre a kérdésre még visszatérünk).

Első ránézésre úgy tűnhet, hogy a kutatás erejének ügye a "gyógyszergyártó saját problémája": megcsinálja a kísérletet, még hat is a gyógyszere, aztán mégis azt kapja, hogy nem hatásos. (Néha szokták is a szignifikanciaszintre azt mondani, hogy a fogyasztó kockázata -- hatástalan gyógyszert kapok -- míg erre a hibára azt, hogy gyártó kockázata -- hat a gyógyszer, és mégsem tudja forgalomba hozni.) Ez első közelítésként rendben van, de valójában ennél kicsit bonyolultabb a helyzet. Ha túl kicsi a vizsgálat ereje (általánosan elterjedt angol szóval: underpowered a kutatás), tehát túl kevés beteget vontak be, akkor a fals hatás kimutatásának a *valószínűsége* tényleg ugyanúgy 5%, mintha közepesen sok, nagyon sok, vagy akármennyi beteget vontak volna be. Igen ám, de *ha* fals hatást mutatunk ki, akkor a kimutatott fals hatás *mértéke* nagyobb lesz akkor, ha kicsi volt a vizsgálat ereje! Ez matematikailag bebizonyítható, de talán intuitíve is érzékeltethető: ha kicsi a mintanagyság, akkor az 5% tartása *épp azért* lesz lehetséges, mert csak nagyon hatásos szerekre mondjuk azt, hogy tényleg hatnak (hiszen ilyenkor nagy az ingadozás, a nem hatásos szerek is könnyebben bizonyulhatnak erősebben hatásosnak pusztán a véletlen ingadozás miatt). Így abban az 5%-ban viszont nagy lesz a kimutatott hatás. Pontosan emiatt valójában kárt okoz az orvosi megismerésnek az is, ha nagy számban készülnek nem megfelelő erejű vizsgálatok [@button2013].

Érdemes végezetül megjegyezni, hogy az erő még egy szempontból fontos: a hatásosnak és a hatástalannak minősítés nem szimmetrikus. Ha a 100 kezeltből mindenki meggyógyul és a 100 kontrollból mindenki meghal, akkor van értelme azt mondani, hogy ez erős bizonyíték a hatásra, de ha pont 50 gyógyul meg itt is meg ott is, az még nem erős bizonyíték arra, hogy nem hat a gyógyszer. Ez azt jelenti, hogy nem tudtunk kimutatni hatást, de ezen állítás nem értelmezhető anélkül, hogy tudnánk, hogy mekkora hatást tudtunk volna egyáltalán kimutatni! Ha kicsi a mintanagyság, kicsi az erő, akkor simán lehet, hogy akár egy nagyobb hatást sem tudunk észrevenni. Gondoljunk arra, hogy ha mindkét csoportban a betegek fele gyógyul meg, az nagyon nem ugyanazt jelenti csoportonként 10, és csoportonként 10 ezer beteggel! Jobban szeretjük azt mondani, hogy "nem tudtuk kimutatni, hogy lenne hatás", ahelyett, hogy "kimutattuk, hogy nincs hatás". Ez utóbbi igazolása sem lehetetlen (természetesen csak olyan értelemben, hogy adott megbízhatósággal kijelenthető módon egy adott küszöbnél kisebb a hatás!), de ez messze többet igényel -- kellően nagy beteglétszámú vizsgálatot -- mint egyszerűen azt, hogy a vizsgálat eredménye nem szignifikáns lett. Szokták néha azt is mondani: a "bizonyíték hiánya nem a hiány bizonyítéka".

## A *p*-érték fogalma

Ha csak annyit tudunk, hogy egy vizsgálat szignifikáns 5%-on, akkor még sok eset lehetséges: elképzelhető, hogy éppen csak nagyobb lett a hatása, mint az 5%-on meghúzott küszöb, de az is elképzelhető, hogy sokkal nagyobb lett. Ha megmondjuk, hogy 5%-on szignifikáns, de 1%-on már nem, akkor már többet tudunk: valahol az 5 és 1%-os küszöbök között van. Ha megmondjuk, hogy 3%-on szignifikáns, de 2%-on nem, akkor még többet tudunk.

Ezt a logikát tovább folytatva eljutunk a ***p-érték*** fogalmához: ez a legkisebb szignifikanciaszint, aminél még éppen hatásosnak minősítenénk a gyógyszert. Azaz: ha ennél nagyobb szignifikanciaszintet választunk, akkor hatásosnak minősítjük a gyógyszert, ha ennél kisebbet, akkor nem. Ha a $p$-érték mondjuk 3,5% (általában így szokták írni: $p=0,\!035$), akkor 5%-ot választva szignifikanciaszintnek hatásosnak minősítjük a gyógyszert, 4%-on szintén, de 3%-on már nem.

A $p$-érték tehát egyrészt számszerűen mutatja, hogy "mennyire" szignifikáns a gyógyszer, másrészt lehetővé teszi, hogy tetszőleges szignifikanciaszinten döntsünk a hatásosságról.

Ha valaki úgy érzi, hogy ez így elég zavaros, az nem véletlen: valójában itt két statisztikai iskola keveredik. Az egyik iskola azt mondja, hogy két lehetőség van, hat a gyógyszer és hatástalan a gyógyszer, ebből adódóan kétféle hibázás van. Meghatározzuk a kétféle hibázás súlyát, ebből matematikailag levezethetjük, hogy mi az optimális szignifikanciaszint (minél nagyobb baj a hatástalan gyógyszer tévesen hatásosnak minősítése, értelemszerűen annál kisebb), és ez alapján döntenünk a két lehetőség között. Itt tehát két lehetőségünk van, egy "igen-nem" típusú döntést hozunk a végén, és nincsen semmilyen $p$-érték. A másik iskola azt mondja, hogy csak egyféle lehetőség van, hogy hatástalan a gyógyszer, mi azt nézzük, hogy ennek mennyire mondanak ellent a vizsgálati eredmények, és ezen ellentmondás mértékét mérjük a $p$-értékkel. Itt tehát egy lehetőség van, ebből adódóan az erő fogalma sem létezik és "igen-nem" típusú döntés helyett egy folytonos, számszerű mérőszámunk lesz, a $p$-érték. Mint láthatjuk, a manapság használt módszer az orvosi vizsgálatok kiértékelésére e két iskola inkonzisztens elegye: van $p$-érték, de mégis két lehetőséget nézünk és "igen-nem" típusú döntést hozunk. Ez az egyik fontos oka annak, hogy nagyon sok vita övezi ennek a módszernek a használatát az orvosi vizsgálatok kiértékelésére, de egyelőre megingathatatlan az uralma [@goodman1999; @wasserstein2016; @greenland2016].

## A konfidenciaintervallum fogalma

A $p$-érték nagy problémája, hogy nem mond semmi szemléleteset sem a hatás nagyságáról, sem az annak becslésében rejlő, véletlen ingadozásból fakadó bizonytalanságról: a $p$-érték lehet ugyanannyi egy olyan esetben, ahol pontosan (nagy mintán) kimértük, hogy a gyógyszer kicsit hat, és egy olyan esetben, ahol pontatlanul (kis mintán) kimértük, hogy nagyon hat. Márpedig ez a kettő nagyon nem ugyanaz, úgyhogy kell valamilyen eszköz, ami erről is számot tud adni: ez lesz a **konfidenciaintervallum**.

A konfidenciaintervallum épp a becsült értékben lévő, véletlen ingadozásból fakadó bizonytalanságot próbálja megragadni. Mit jelent a véletlen ingadozás? Az, hogy ha a valódi érték 15%, a mintámban kaphatok 10-et vagy épp 20-at is. Ugyanez fordítva elmondva: ha 10%-ot kaptam, a valódi érték lehetett 15 (de éppenséggel 5 is). A kérdés tehát az, hogy ha 10%-ot kaptam, akkor mi lehetett a valódi érték? Ahogy korábban is láttuk, erre nem tudunk válaszolni, de a fordított kérdésre igen: milyen értékekre igaz, hogy ha ennyi lenne a valóság, akkor kijöhetett 10% pusztán a véletlen ingadozás miatt. Melyek azok az értékek, amelyek ilyen értelemben "hihetőek", mint valóság, ha a mintában megfigyelt eredményekre támaszkodunk csupán -- ezt adja meg a konfidenciaintervallum. Ha például a 10% konfidenciaintervalluma a 8%, 12% tartomány, az azt jelenti, hogy ha 8 és 12% között lenne a valódi érték, akkor még nem elhanyagolható valószínűséggel kijöhet 10% pusztán a véletlen ingadozás miatt, de ha 8-nál kisebb, vagy 12-nél nagyobb lenne a valódi érték, akkor már nagyon valószínűtlen lenne, hogy pusztán a véletlen ingadozás miatt 10-et kapjunk. Azt, hogy mit értünk "nem elhanyagolható" valószínűségen, meg "nagyon valószínűtlen" alatt az ún. megbízhatósági szint adja meg, a tipikus értéke 95%. Ami ebben benne van, azoktól az értékektől nem különbözik szignifikánsan az eredményünk, ha 5%-os szignifikanciaszintet használunk.

## Statisztikai szignifikancia és klinikai relevancia

Az előbbiekben végig a statisztikai értelemben vett szignifikanciáról volt szó: arról, hogy egy vizsgálatban talált hatás van-e olyan nagy, hogy azt gondoljuk róla, hogy valódi hatás van-e a hátterében, vagy pedig el tudjuk fogadni, hogy nincs valódi hatás, és a vizsgálatban tapasztalt hatás kijöhetett pusztán a véletlen ingadozás miatt. A "szignifikáns" szónak azonban van egy teljesen más értelme is, az, hogy a hatás nagysága akkora, ami az adott tárgyterületen szakmailag lényeges: "a betegnek tegnap óta szignifikánsan csökkent a vérnyomása" (mert 180/140-ről lement 120/80-ra). Ez egy teljesen értelmes és érthető mondat, de az is világos, hogy az itt használt szignifikanciának semmi köze az előbbi értelemhez, úgyhogy megkülönböztetésül ezt nevezzük **klinikai relevanciának**. Azonban a mindennapi szóhasználatban a kétféle jelentés gyakran keveredik.

A probléma, hogy egyik jelentésből sem következik a másik: egy hatás lehet statisztikailag szignifikáns, de klinikailag nem, ám lehet klinikailag szignifikáns is úgy, hogy közben meg statisztikailag nem az. Hogy hogyan? A választ az előző pont adja meg: a dolog a hatás becslésének véletlen ingadozásból fakadó bizonytalanságán, például a mintanagyságon múlik! Lehet, hogy a gyógyszer klinikailag nagyon is szignifikánsan, 20 Hgmm-rel csökkenti a vérnyomást, de ez statisztikailag inszignifikáns (mert 4 betegen mérték ki), és lehet, hogy klinikailag teljesen inszignifikánsan, 0,2 Hgmm-rel csökkenti a vérnyomást, de ez mégis szignifikáns statisztikailag (mert 4000 betegen mérték ki).

Pontosan ezért oda kell figyelni arra, hogy ha a szignifikáns szót látjuk, akkor azt milyen értelemben használják: attól még mert valami statisztikailag szignifikáns, a hatás mérete lehet bármilyen kicsi, adott esetben minden klinikai jelentőség nélküli is.